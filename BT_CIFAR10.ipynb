{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BT-CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Testing a Barlow Twins trained RESNET50 with a classifier head for CIFAR10\n",
        "For this test, we build our DNN with the RESNET50 from the Barlow Twins group as a backbone and a fully connected layer as our classifier head."
      ],
      "metadata": {
        "id": "Mox_5RrleDJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# Download TorchVision repo to use some files from\n",
        "# references/detection\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.8.2\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTw57S_IJ8FU",
        "outputId": "61dc5061-59e3-4c74-8cfd-ef5b6e27fb3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 79885, done.\u001b[K\n",
            "remote: Counting objects: 100% (15019/15019), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1349/1349), done.\u001b[K\n",
            "remote: Total 79885 (delta 13796), reused 14696 (delta 13590), pack-reused 64866\n",
            "Receiving objects: 100% (79885/79885), 156.09 MiB | 41.11 MiB/s, done.\n",
            "Resolving deltas: 100% (66867/66867), done.\n",
            "Note: checking out 'v0.8.2'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 2f40a483d [v0.8.X] .circleci: Add Python 3.9 to CI (#3063)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "from torchvision import models, datasets, transforms\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from engine import evaluate"
      ],
      "metadata": {
        "id": "pXz1XnYzgMGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "id": "cmcXEjmvgzsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGWOmMwkd-Xe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69589370-39ed-43c1-a641-b0d5fa66da73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10\n",
        "model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50', pretrained=True)\n",
        "set_parameter_requires_grad(model, feature_extracting=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking and assigning the parameters to update. (Must only be the weights and biases for the full connected layer)"
      ],
      "metadata": {
        "id": "777iNYCrfAUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = []\n",
        "for name,param in model.named_parameters():\n",
        "  if param.requires_grad == True:\n",
        "    params_to_update.append(param)\n",
        "    print(\"\\t\",name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAqOkf-we_0J",
        "outputId": "59dbba71-e97c-42a9-d8d2-5fccbf89d46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the transforms for the train data and calling the CIFAR10 dataset."
      ],
      "metadata": {
        "id": "xZbnW-SyfB9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTransforms = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "TestTransforms = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "trainset = datasets.CIFAR10(root=\"data/cifar10\", train=True, download=True, transform=TrainTransforms)\n",
        "testset = datasets.CIFAR10(root=\"data/cifar10\", train=False, download=True, transform=TestTransforms)"
      ],
      "metadata": {
        "id": "dcsWGISAeflG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a620f37c-d574-41d2-98d7-23cc5d89421e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the classes for the CIFAR10 dataset"
      ],
      "metadata": {
        "id": "dBnkF0L1hlhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Airplane', 'Car', 'Bird','Cat','Deer','Dog','Frog','Horse','Ship','Truck']"
      ],
      "metadata": {
        "id": "BRNaoCt0hky7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading sample images to test the classification."
      ],
      "metadata": {
        "id": "gNgnRvprhtWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cdn.hswstatic.com/gif/airplane-windows.jpg -O 'test1.jpg'\n",
        "!wget https://www.irmi.com/images/default-source/article-images/aviation/boeing-737.jpg -O 'test2.jpg'\n",
        "!wget https://images.frandroid.com/wp-content/uploads/2021/11/apple-car-concept.jpg -O 'test3.jpg'\n",
        "!wget https://abcbirds.org/wp-content/uploads/2021/07/Blue-Jay-on-redbud-tree-by-Tom-Reichner_news.png -O 'test4.jpg'\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/4/4d/Cat_November_2010-1a.jpg -O 'test5.jpg'\n",
        "!wget https://iadsb.tmgrup.com.tr/7ddb86/0/0/0/0/1926/1086?u=https://idsb.tmgrup.com.tr/2018/05/22/horses-the-wings-of-mankind-1527015927739.jpg -O 'test6.jpg'\n",
        "!wget https://carwow-uk-wp-3.imgix.net/Volvo-XC40-white-scaled.jpg -O 'test7.jpg'\n",
        "!wget https://media.self.com/photos/6192b264fd75b7baf2aadbe1/4:3/w_2560%2Cc_limit/GettyImages-1219359156.jpg -O 'test8.jpg'\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/d/d9/Motorboat_at_Kankaria_lake.JPG -O 'test9.jpg'\n",
        "!wget https://cdn.britannica.com/84/206384-050-00698723/Javan-gliding-tree-frog.jpg -O 'test10.jpg'"
      ],
      "metadata": {
        "id": "girNYaqehrf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b57c39-7904-4522-b38b-7846b02bdd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-20 16:53:10--  https://cdn.hswstatic.com/gif/airplane-windows.jpg\n",
            "Resolving cdn.hswstatic.com (cdn.hswstatic.com)... 13.32.204.8, 13.32.204.52, 13.32.204.21, ...\n",
            "Connecting to cdn.hswstatic.com (cdn.hswstatic.com)|13.32.204.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 107448 (105K) [image/jpeg]\n",
            "Saving to: ‘test1.jpg’\n",
            "\n",
            "\rtest1.jpg             0%[                    ]       0  --.-KB/s               \rtest1.jpg           100%[===================>] 104.93K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-01-20 16:53:10 (33.2 MB/s) - ‘test1.jpg’ saved [107448/107448]\n",
            "\n",
            "--2022-01-20 16:53:10--  https://www.irmi.com/images/default-source/article-images/aviation/boeing-737.jpg\n",
            "Resolving www.irmi.com (www.irmi.com)... 104.18.162.71, 104.18.163.71, 2606:4700::6812:a347, ...\n",
            "Connecting to www.irmi.com (www.irmi.com)|104.18.162.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48515 (47K) [image/jpeg]\n",
            "Saving to: ‘test2.jpg’\n",
            "\n",
            "test2.jpg           100%[===================>]  47.38K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-20 16:53:11 (145 MB/s) - ‘test2.jpg’ saved [48515/48515]\n",
            "\n",
            "--2022-01-20 16:53:11--  https://images.frandroid.com/wp-content/uploads/2021/11/apple-car-concept.jpg\n",
            "Resolving images.frandroid.com (images.frandroid.com)... 104.25.188.67, 172.67.82.116, 104.25.187.67, ...\n",
            "Connecting to images.frandroid.com (images.frandroid.com)|104.25.188.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 99879 (98K) [image/jpeg]\n",
            "Saving to: ‘test3.jpg’\n",
            "\n",
            "test3.jpg           100%[===================>]  97.54K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-01-20 16:53:12 (33.7 MB/s) - ‘test3.jpg’ saved [99879/99879]\n",
            "\n",
            "--2022-01-20 16:53:12--  https://abcbirds.org/wp-content/uploads/2021/07/Blue-Jay-on-redbud-tree-by-Tom-Reichner_news.png\n",
            "Resolving abcbirds.org (abcbirds.org)... 146.148.94.247\n",
            "Connecting to abcbirds.org (abcbirds.org)|146.148.94.247|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116918 (114K) [image/png]\n",
            "Saving to: ‘test4.jpg’\n",
            "\n",
            "test4.jpg           100%[===================>] 114.18K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-01-20 16:53:12 (1.88 MB/s) - ‘test4.jpg’ saved [116918/116918]\n",
            "\n",
            "--2022-01-20 16:53:12--  https://upload.wikimedia.org/wikipedia/commons/4/4d/Cat_November_2010-1a.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2833605 (2.7M) [image/jpeg]\n",
            "Saving to: ‘test5.jpg’\n",
            "\n",
            "test5.jpg           100%[===================>]   2.70M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-01-20 16:53:12 (29.0 MB/s) - ‘test5.jpg’ saved [2833605/2833605]\n",
            "\n",
            "--2022-01-20 16:53:12--  https://iadsb.tmgrup.com.tr/7ddb86/0/0/0/0/1926/1086?u=https://idsb.tmgrup.com.tr/2018/05/22/horses-the-wings-of-mankind-1527015927739.jpg\n",
            "Resolving iadsb.tmgrup.com.tr (iadsb.tmgrup.com.tr)... 52.85.135.26, 52.85.135.16, 52.85.135.31, ...\n",
            "Connecting to iadsb.tmgrup.com.tr (iadsb.tmgrup.com.tr)|52.85.135.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 355331 (347K) [image/jpeg]\n",
            "Saving to: ‘test6.jpg’\n",
            "\n",
            "test6.jpg           100%[===================>] 347.00K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2022-01-20 16:53:12 (46.1 MB/s) - ‘test6.jpg’ saved [355331/355331]\n",
            "\n",
            "--2022-01-20 16:53:12--  https://carwow-uk-wp-3.imgix.net/Volvo-XC40-white-scaled.jpg\n",
            "Resolving carwow-uk-wp-3.imgix.net (carwow-uk-wp-3.imgix.net)... 151.101.202.208, 2a04:4e42:50::720\n",
            "Connecting to carwow-uk-wp-3.imgix.net (carwow-uk-wp-3.imgix.net)|151.101.202.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 392650 (383K) [image/jpeg]\n",
            "Saving to: ‘test7.jpg’\n",
            "\n",
            "test7.jpg           100%[===================>] 383.45K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2022-01-20 16:53:12 (88.2 MB/s) - ‘test7.jpg’ saved [392650/392650]\n",
            "\n",
            "--2022-01-20 16:53:12--  https://media.self.com/photos/6192b264fd75b7baf2aadbe1/4:3/w_2560%2Cc_limit/GettyImages-1219359156.jpg\n",
            "Resolving media.self.com (media.self.com)... 151.101.0.239, 151.101.64.239, 151.101.128.239, ...\n",
            "Connecting to media.self.com (media.self.com)|151.101.0.239|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 535184 (523K) [image/jpeg]\n",
            "Saving to: ‘test8.jpg’\n",
            "\n",
            "test8.jpg           100%[===================>] 522.64K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2022-01-20 16:53:12 (84.6 MB/s) - ‘test8.jpg’ saved [535184/535184]\n",
            "\n",
            "--2022-01-20 16:53:13--  https://upload.wikimedia.org/wikipedia/commons/d/d9/Motorboat_at_Kankaria_lake.JPG\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2850816 (2.7M) [image/jpeg]\n",
            "Saving to: ‘test9.jpg’\n",
            "\n",
            "test9.jpg           100%[===================>]   2.72M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-01-20 16:53:13 (29.1 MB/s) - ‘test9.jpg’ saved [2850816/2850816]\n",
            "\n",
            "--2022-01-20 16:53:13--  https://cdn.britannica.com/84/206384-050-00698723/Javan-gliding-tree-frog.jpg\n",
            "Resolving cdn.britannica.com (cdn.britannica.com)... 52.85.151.34, 52.85.151.114, 52.85.151.120, ...\n",
            "Connecting to cdn.britannica.com (cdn.britannica.com)|52.85.151.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 229131 (224K) [image/jpeg]\n",
            "Saving to: ‘test10.jpg’\n",
            "\n",
            "test10.jpg          100%[===================>] 223.76K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2022-01-20 16:53:13 (30.6 MB/s) - ‘test10.jpg’ saved [229131/229131]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_test = ['./test1.jpg','./test2.jpg','./test3.jpg','./test4.jpg','./test5.jpg','./test6.jpg','./test7.jpg','./test8.jpg','./test9.jpg','./test10.jpg']\n",
        "label_test = ['Airplane','Airplane','Car', 'Bird', 'Cat', 'Horse', 'Car', 'Deer', 'Ship','Frog']"
      ],
      "metadata": {
        "id": "XGYorBSJbUHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a train function to train the classifier head."
      ],
      "metadata": {
        "id": "pZbZsUVNfHuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, dataloader_test, path_test, label_test, params, nepochs=1, lr=1e-3):\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    optimizer = torch.optim.Adam(params,weight_decay=1e-5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    running_loss = 0.\n",
        "    running_samples = 0\n",
        "    for epoch in range(nepochs):\n",
        "        model.train()\n",
        "        for it, data in enumerate(dataloader):\n",
        "            ims, labels = data\n",
        "            ims = ims.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(ims)\n",
        "            loss = criterion(out, labels)\n",
        "            running_loss += loss\n",
        "            running_samples += ims.shape[0]\n",
        "\n",
        "            if it % 100 == 0:\n",
        "                print(f'ep: {epoch}, it: {it}, loss : {running_loss/running_samples:.5f}')\n",
        "                running_loss = 0.\n",
        "                running_samples = 0\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        accuracy = test(model, dataloader_test, device)\n",
        "        print(f'The accuracy on the test dataset for epoch {epoch} is: {accuracy}%')\n",
        "        accuracy = TestModelCustomBatch(model, path_test, label_test)\n",
        "        print(f'The accuracy on the test dataset for epoch {epoch} is: {accuracy}%')"
      ],
      "metadata": {
        "id": "t-bcTt1nejiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader_test, device):\n",
        "  model.eval()\n",
        "  correct_labels = 0\n",
        "  total_labels = 0\n",
        "  with torch.no_grad():\n",
        "    for data in dataloader_test:\n",
        "      ims, labels = data\n",
        "      ims = ims.to(device)\n",
        "      out = model(ims)\n",
        "      for i, label in enumerate(labels):\n",
        "        if label.item() == torch.argmax(out[i]).item():\n",
        "          correct_labels += 1\n",
        "      total_labels += labels.shape[0]\n",
        "  accuracy = correct_labels/total_labels*100\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "rBnVh2V9MQHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TestModelCustomBatch(model,img_paths,expected):\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "  count = 0\n",
        "  total = 0\n",
        "  for it, img_path in enumerate(img_paths):\n",
        "      \n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )])\n",
        "    img = preprocess(img)\n",
        "    batch_img = torch.unsqueeze(img,0)\n",
        "    model.eval()\n",
        "    batch_img = batch_img.to(device)\n",
        "    with torch.no_grad():\n",
        "      out = model(batch_img)\n",
        "\n",
        "    out = out.cpu()\n",
        "    out = out.squeeze()\n",
        "    #print(f'{classes[torch.argmax(out).item()]:15} | {expected:15}')\n",
        "    if classes[torch.argmax(out).item()] == expected[it]:\n",
        "      count += 1\n",
        "    total += 1\n",
        "\n",
        "  accuracy = count/total*100\n",
        "  return accuracy\n"
      ],
      "metadata": {
        "id": "Yf7o9nrRbnE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the classifier head of the Barlow Twins model."
      ],
      "metadata": {
        "id": "_xfXW3zvfPvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = trainset[0][0].shape\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=100)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=25)\n",
        "train(model, train_loader, test_loader,path_test,label_test,params_to_update, nepochs=10, lr=1e-3)"
      ],
      "metadata": {
        "id": "7tFUufmhfN2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b72059bf-c501-4421-e491-eafdaf20d29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 0, it: 0, loss : 0.02305\n",
            "ep: 0, it: 100, loss : 0.01754\n",
            "ep: 0, it: 200, loss : 0.01165\n",
            "ep: 0, it: 300, loss : 0.00925\n",
            "ep: 0, it: 400, loss : 0.00824\n",
            "The accuracy on the test dataset for epoch 0 is: 80.05%\n",
            "The accuracy on the test dataset for epoch 0 is: 50.0%\n",
            "ep: 1, it: 0, loss : 0.00735\n",
            "ep: 1, it: 100, loss : 0.00675\n",
            "ep: 1, it: 200, loss : 0.00643\n",
            "ep: 1, it: 300, loss : 0.00602\n",
            "ep: 1, it: 400, loss : 0.00592\n",
            "The accuracy on the test dataset for epoch 1 is: 83.28%\n",
            "The accuracy on the test dataset for epoch 1 is: 60.0%\n",
            "ep: 2, it: 0, loss : 0.00559\n",
            "ep: 2, it: 100, loss : 0.00534\n",
            "ep: 2, it: 200, loss : 0.00525\n",
            "ep: 2, it: 300, loss : 0.00504\n",
            "ep: 2, it: 400, loss : 0.00510\n",
            "The accuracy on the test dataset for epoch 2 is: 84.55%\n",
            "The accuracy on the test dataset for epoch 2 is: 60.0%\n",
            "ep: 3, it: 0, loss : 0.00485\n",
            "ep: 3, it: 100, loss : 0.00467\n",
            "ep: 3, it: 200, loss : 0.00466\n",
            "ep: 3, it: 300, loss : 0.00452\n",
            "ep: 3, it: 400, loss : 0.00462\n",
            "The accuracy on the test dataset for epoch 3 is: 85.47%\n",
            "The accuracy on the test dataset for epoch 3 is: 60.0%\n",
            "ep: 4, it: 0, loss : 0.00439\n",
            "ep: 4, it: 100, loss : 0.00434\n",
            "ep: 4, it: 200, loss : 0.00433\n",
            "ep: 4, it: 300, loss : 0.00422\n",
            "ep: 4, it: 400, loss : 0.00429\n",
            "The accuracy on the test dataset for epoch 4 is: 86.06%\n",
            "The accuracy on the test dataset for epoch 4 is: 60.0%\n",
            "ep: 5, it: 0, loss : 0.00411\n",
            "ep: 5, it: 100, loss : 0.00408\n",
            "ep: 5, it: 200, loss : 0.00407\n",
            "ep: 5, it: 300, loss : 0.00397\n",
            "ep: 5, it: 400, loss : 0.00405\n",
            "The accuracy on the test dataset for epoch 5 is: 86.53999999999999%\n",
            "The accuracy on the test dataset for epoch 5 is: 60.0%\n",
            "ep: 6, it: 0, loss : 0.00388\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-69fd04f330b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_to_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-1f78ccdaabbe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, dataloader_test, path_test, label_test, params, nepochs, lr)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the function for testing."
      ],
      "metadata": {
        "id": "ABffj1KEh1HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TestModel(model,img_path,expected):\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "  #showimg = cv2.imread(img_path)\n",
        "  #cv2_imshow(showimg)\n",
        "  img = Image.open(img_path).convert('RGB')\n",
        "  preprocess = transforms.Compose([\n",
        "          transforms.Resize(256),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(\n",
        "          mean=[0.485, 0.456, 0.406],\n",
        "          std=[0.229, 0.224, 0.225]\n",
        "      )])\n",
        "  img = preprocess(img)\n",
        "  batch_img = torch.unsqueeze(img,0)\n",
        "  model.eval()\n",
        "  batch_img = batch_img.to(device)\n",
        "  with torch.no_grad():\n",
        "    out = model(batch_img)\n",
        "\n",
        "  out = out.cpu()\n",
        "  out = out.squeeze()\n",
        "  #print(f'The classification of this image according to Barlow Twins is:{classes[torch.argmax(out).item()]}')\n",
        "  print(f'{classes[torch.argmax(out).item()]:15} | {expected:15}')\n",
        "  #print(out)"
      ],
      "metadata": {
        "id": "VGdVcbYDh1gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing the tests."
      ],
      "metadata": {
        "id": "8gCqLFXlh6CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Barlow Twins    | Expected')\n",
        "TestModel(model, './test1.jpg', 'Airplane')\n",
        "TestModel(model, './test2.jpg', 'Airplane')\n",
        "TestModel(model, './test3.jpg', 'Car')\n",
        "TestModel(model, './test4.jpg', 'Bird')\n",
        "TestModel(model, './test5.jpg', 'Cat')\n",
        "TestModel(model, './test6.jpg', 'Horse')\n",
        "TestModel(model, './test7.jpg', 'Car')\n",
        "TestModel(model, './test8.jpg', 'Deer')\n",
        "TestModel(model, './test9.jpg', 'Ship')\n",
        "TestModel(model, './test10.jpg', 'Frog')"
      ],
      "metadata": {
        "id": "wMzvlx45h7y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c1ec557-d7cb-465e-d018-0d251dfbf09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Barlow Twins    | Expected\n",
            "Airplane        | Airplane       \n",
            "Airplane        | Airplane       \n",
            "Airplane        | Car            \n",
            "Bird            | Bird           \n",
            "Bird            | Cat            \n",
            "Airplane        | Horse          \n",
            "Car             | Car            \n",
            "Deer            | Deer           \n",
            "Airplane        | Ship           \n",
            "Airplane        | Frog           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing a Barlow Twins trained RESNET50 with a classifier head for TinyImageNet\n",
        "Since we already have the code for our model above, we will begin with downloading and preprocessing the data of the TinyImageNet dataset."
      ],
      "metadata": {
        "id": "aNB4U6bpmOPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nArtMhSUmnc4",
        "outputId": "e419306a-5b82-47f6-d373-5ee64a9c265b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IMagenet'...\n",
            "remote: Enumerating objects: 120594, done.\u001b[K\n",
            "remote: Total 120594 (delta 0), reused 0 (delta 0), pack-reused 120594\u001b[K\n",
            "Receiving objects: 100% (120594/120594), 212.68 MiB | 34.51 MiB/s, done.\n",
            "Resolving deltas: 100% (1115/1115), done.\n",
            "Checking out files: 100% (120206/120206), done.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import scipy.ndimage as nd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [plt.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i))) for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(plt.imread( path + 'val/images/{}'.format(img_name)))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return train_data, train_labels, test_data, test_labels\n",
        "  \n",
        "train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESmmJDPYnf08",
        "outputId": "f62da2cf-204a-4de8-8784-b2ce37d283fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting loading data\n",
            "finished loading data, in 29.7906277179718 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_data:\n",
        "  print(f'The:{len(data)}{len(data[0])}{len(data[0][0])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "60uWZPL8woGc",
        "outputId": "48d88443-c11e-4ea3-f0f1-e6ff162d18a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n",
            "The:64643\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-0c9bd33a6c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The:{len(data)}{len(data[0])}{len(data[0][0])}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.uint8' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.array(train_data)\n",
        "print( \"train data shape: \",  train_data.shape )\n",
        "print( \"train label shape: \", train_labels.shape )\n",
        "print( \"test data shape: \",   test_data.shape )\n",
        "print( \"test_labels.shape: \", test_labels.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "qadxS88Is9uK",
        "outputId": "6e0eca1a-f47a-4d54-c976-a67a76ba68cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-13a9ea97bcae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"train data shape: \"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"train label shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"test data shape: \"\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"test_labels.shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (64,64,3) into shape (64,64)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training a Barlow Twins model"
      ],
      "metadata": {
        "id": "RKfNu-xrCN_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing libraries."
      ],
      "metadata": {
        "id": "URK__xbPgRkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "from torch.autograd import Variable\n",
        "import random\n",
        "from torchvision import models, datasets, transforms\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "VFN04NvCCVgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "fcnuVr2UgG0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Barlow Twins class for the model."
      ],
      "metadata": {
        "id": "CTQx5evGgMuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BarlowTwins(nn.Module):\n",
        "  def __init__(self, lambd=0.0051):\n",
        "    super().__init__()\n",
        "    self.lambd = lambd\n",
        "    #ResNet50\n",
        "    self.backbone = torchvision.models.resnet50(zero_init_residual=True)\n",
        "    self.backbone.fc = nn.Identity()\n",
        "    #Projector\n",
        "    sizes = [2048, 8192,8192,8192]\n",
        "    layers = []\n",
        "    for i in range(len(sizes) - 2):\n",
        "      layers.append(nn.Linear(sizes[i], sizes[i + 1], bias=False))\n",
        "      layers.append(nn.BatchNorm1d(sizes[i + 1]))\n",
        "      layers.append(nn.ReLU(inplace=True))\n",
        "    layers.append(nn.Linear(sizes[-2], sizes[-1], bias=False))\n",
        "    self.projector = nn.Sequential(*layers)\n",
        "    #NormalizationLayer\n",
        "    self.bn = nn.BatchNorm1d(sizes[-1], affine=False)\n",
        "\n",
        "  def forward(self, y1, y2):\n",
        "    z1 = self.projector(self.backbone(y1))\n",
        "    z2 = self.projector(self.backbone(y2))\n",
        "\n",
        "    # empirical cross-correlation matrix\n",
        "    c = self.bn(z1).T @ self.bn(z2)\n",
        "\n",
        "    # sum the cross-correlation matrix between all gpus\n",
        "    #c.div_(self.args.batch_size)\n",
        "    #torch.distributed.all_reduce(c)\n",
        "\n",
        "    on_diag = torch.diagonal(c).add_(-1).pow_(2).sum()\n",
        "    off_diag = off_diagonal(c).pow_(2).sum()\n",
        "    loss = on_diag + self.lambd * off_diag\n",
        "    return loss"
      ],
      "metadata": {
        "id": "f6unZTIrgJqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def off_diagonal(x):\n",
        "    # return a flattened view of the off-diagonal elements of a square matrix\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()"
      ],
      "metadata": {
        "id": "wcMNtT_vFkXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mimicking the optimizer the Facebook Group used for the Barlow Twins training."
      ],
      "metadata": {
        "id": "Wgz7MSqjgM48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LARS(optim.Optimizer):\n",
        "  def __init__(self, params, lr, weight_decay=0, momentum=0.9, eta=0.001, weight_decay_filter=False, lars_adaptation_filter=False):\n",
        "    defaults = dict(lr=lr, weight_decay=weight_decay, momentum=momentum, eta=eta, weight_decay_filter=weight_decay_filter, lars_adaptation_filter=lars_adaptation_filter)\n",
        "    super().__init__(params, defaults)\n",
        "  def exclude_bias_and_norm(self, p):\n",
        "    return p.ndim == 1\n",
        "  \n",
        "  @torch.no_grad()\n",
        "  def step(self):\n",
        "    for g in self.param_groups:\n",
        "      for p in g['params']:\n",
        "        dp = p.grad\n",
        "        if dp is None:\n",
        "          continue\n",
        "        if not g['weight_decay_filter'] or not self.exclude_bias_and_norm(p):\n",
        "          dp = dp.add(p, alpha=g['weight_decay'])\n",
        "        if not g['lars_adaptation_filter'] or not self.exclude_bias_and_norm(p):\n",
        "          param_norm = torch.norm(p)\n",
        "          update_norm = torch.norm(dp)\n",
        "          one = torch.ones_like(param_norm)\n",
        "          q = torch.where(param_norm > 0., torch.where(update_norm > 0, (g['eta'] * param_norm / update_norm), one), one)\n",
        "          dp = dp.mul(q)\n",
        "        param_state = self.state[p]\n",
        "        if 'mu' not in param_state:\n",
        "          param_state['mu'] = torch.zeros_like(p)\n",
        "        mu = param_state['mu']\n",
        "        mu.mul_(g['momentum']).add_(dp)\n",
        "        p.add_(mu, alpha=-g['lr'])"
      ],
      "metadata": {
        "id": "9a3rwUJAgawK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the transforms."
      ],
      "metadata": {
        "id": "MlshBJGtgeST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianBlur(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if random.random() < self.p:\n",
        "            sigma = random.random() * 1.9 + 0.1\n",
        "            return img.filter(ImageFilter.GaussianBlur(sigma))\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "\n",
        "class Solarization(object):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if random.random() < self.p:\n",
        "            return ImageOps.solarize(img)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "\n",
        "class Transform:\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, interpolation=Image.BICUBIC),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomApply(\n",
        "                [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
        "                                        saturation=0.2, hue=0.1)],\n",
        "                p=0.8\n",
        "            ),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            GaussianBlur(p=1.0),\n",
        "            Solarization(p=0.0),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        self.transform_prime = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, interpolation=Image.BICUBIC),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomApply(\n",
        "                [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
        "                                        saturation=0.2, hue=0.1)],\n",
        "                p=0.8\n",
        "            ),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            GaussianBlur(p=0.1),\n",
        "            Solarization(p=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        y1 = self.transform(x)\n",
        "        y2 = self.transform_prime(x)\n",
        "        return y1, y2"
      ],
      "metadata": {
        "id": "tRULnS-2gblU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing the model, the parameters and the optimizer."
      ],
      "metadata": {
        "id": "FEzOiiiugf-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BarlowTwins()\n",
        "#model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
        "\n",
        "param_weights = []\n",
        "param_biases = []\n",
        "\n",
        "for param in model.parameters():\n",
        "  if param.ndim == 1:\n",
        "    param_biases.append(param)\n",
        "  else:\n",
        "    param_weights.append(param)\n",
        "\n",
        "parameters = [{'params': param_weights}, {'params': param_biases}]\n",
        "optimizer = LARS(parameters, lr=0, weight_decay=1e-6, weight_decay_filter=True, lars_adaptation_filter=True)\n",
        "\n",
        "#DO SOMETHING LIKE THIS IF WE WANT TO WORK ON MULTIPLE GPUs.\n",
        "#model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[device])\n",
        "\n"
      ],
      "metadata": {
        "id": "4oX0ZATyggSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IF WE WANT TO USE THE CHECKPOINT:\n",
        "(Otherwise, don't use)"
      ],
      "metadata": {
        "id": "zfqD8vHvg3Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = torch.load('/content/drive/MyDrive/MIR/1stSemester/DeepLearning/BarlowTwins/checkpoint.pth')\n",
        "\n",
        "#Changing nomenclature to match with model.\n",
        "for key in list(ckpt['model'].keys()):\n",
        "  ckpt['model'][key.replace('module.backbone', 'backbone').replace('module.projector','projector').replace('module.bn','bn')] = ckpt['model'].pop(key)\n",
        "\n",
        "start_epoch = ckpt['epoch']\n",
        "model.load_state_dict(ckpt['model'])\n",
        "optimizer.load_state_dict(ckpt['optimizer'])\n",
        "\n",
        "### To read the dictionary for the weights in the model ###\n",
        "#for param_tensor in ckpt['model']:\n",
        "#  print(param_tensor, \"\\t\", ckpt['model'][param_tensor].size())"
      ],
      "metadata": {
        "id": "MeEvlBbFg5Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the dataset:"
      ],
      "metadata": {
        "id": "cY9qyIedhIBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1LOM-2A1BSLaFjCY2EEK3DA2Lo37rNw-7\n",
        "!unzip -oq underwater_imagenet.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfXWS9h0iguh",
        "outputId": "8db7f4e7-0c7f-4352-aef6-b7c0a8afe41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LOM-2A1BSLaFjCY2EEK3DA2Lo37rNw-7\n",
            "To: /content/underwater_imagenet.zip\n",
            "100% 449M/449M [00:02<00:00, 168MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image as im\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "piCglZQy-Kob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, imgs, transform=None, target_transform=None):\n",
        "      self.imgs = imgs\n",
        "      self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      sample = im.fromarray(self.imgs[idx])\n",
        "      #sample = self.imgs[idx]\n",
        "      if self.transform:\n",
        "        y1, y2 = self.transform(sample)\n",
        "      return y1, y2"
      ],
      "metadata": {
        "id": "TjfcxeyX1XCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "filelist = glob.glob('/content/underwater_imagenet/trainA/*.jpg')\n",
        "train_imgs = np.array([np.array(Image.open(fname)) for fname in filelist])"
      ],
      "metadata": {
        "id": "8YTCkQen8rBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = Transform()\n",
        "train_set = CustomDataset(train_imgs,transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rRXAnxn9ISq",
        "outputId": "b2d242dd-963d-461f-fd56-527036cca425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:853: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 5\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "#torch.distributed.init_process_group(backend='nccl',rank=)\n",
        "#model = model.to(device)\n",
        "#optimizer = optimizer.to(device)\n",
        "for episode in tqdm(range(episodes)):\n",
        "  for it, (y1, y2) in enumerate(train_loader):\n",
        "    model = model.to(device)\n",
        "    y1 = y1.to(device)\n",
        "    y2 = y2.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    loss = model(y1,y2)\n",
        "    loss.backward()\n",
        "    model = model.cpu()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "-ZxyqXWi3_hC",
        "outputId": "c86b4c01-88e8-433e-853e-6c5c1753d44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [19:26<1:17:45, 1166.33s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-17666b5eab58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \"\"\"\n\u001b[0;32m--> 710\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                     \u001b[0mgrad_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \"\"\"\n\u001b[0;32m--> 710\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}